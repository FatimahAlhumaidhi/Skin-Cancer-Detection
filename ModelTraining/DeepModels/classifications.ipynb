{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import getModel \n",
    "from dataloader import data_pipeline #, data_pipeline_with_augmentation\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB5\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB7 \n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, CSVLogger, EarlyStopping \n",
    "from tensorflow.keras.models import load_model \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import pandas as pd\n",
    "import pickle, os, shutil\n",
    "from IPython.display import clear_output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    'classification',\n",
    "    'classificationWithGAN',\n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "for dataset in datasets:\n",
    "    subprocess.Popen(f\"unzip 'drive/MyDrive/{dataset}.zip'\", shell=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preTrained = {\n",
    "    'VGG16' : dict(\n",
    "      modelFunction = VGG16,\n",
    "      learningRate = 7e-5, \n",
    "      batchSize = 8,\n",
    "      pool = 'max',\n",
    "      dropout = [0.6, 0.5],\n",
    "      trainbatchnorm = False,\n",
    "      denseSize = [512, 32],\n",
    "      epochs = 14\n",
    "    ),\n",
    "    'ResNet50V2' : dict(\n",
    "      modelFunction = ResNet50V2,\n",
    "      learningRate = 7e-5, \n",
    "      batchSize = 8,\n",
    "      pool = 'avg',\n",
    "      dropout = [0.5, 0.4],\n",
    "      trainbatchnorm = True,\n",
    "      denseSize = [512, 32],\n",
    "      epochs = 12\n",
    "    ),\n",
    "    'EfficientNetB5' : dict(\n",
    "      modelFunction = EfficientNetB5,\n",
    "      learningRate = 7e-5, \n",
    "      batchSize = 8,\n",
    "      pool = 'max',\n",
    "      dropout = [0.6, 0.4],\n",
    "      trainbatchnorm = False,\n",
    "      denseSize = [512, 256],\n",
    "      epochs = 10\n",
    "    ),\n",
    "    'EfficientNetB7' : dict(\n",
    "      modelFunction = EfficientNetB7,\n",
    "      learningRate = 7e-5, \n",
    "      batchSize = 8,\n",
    "      pool = 'max',\n",
    "      dropout = [0.6, 0.3],\n",
    "      trainbatchnorm = False,\n",
    "      denseSize = [512, 256],\n",
    "      epochs = 4\n",
    "    ),\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf results \n",
    "os.mkdir('results') \n",
    "for dataset in datasets:\n",
    "  os.mkdir(f'results/{dataset}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "def train():\n",
    "  for preTrainedModel in preTrained.keys():\n",
    "      for dataset in datasets:\n",
    "        modelFunction, learningRate, batchSize, pool, dropout, trainbatchnorm, denseSize, epochs = preTrained[preTrainedModel].values()\n",
    "        epochs = 10\n",
    "        trainDataset, validateDataset, testDataset = data_pipeline(DIR=dataset, BATCHSIZE=batchSize) \n",
    "        model = getModel(modelFunction, learning_rate=learningRate, trainbatchnorm=trainbatchnorm, pool=pool, dropout=dropout, denseSize=denseSize)\n",
    "\n",
    "        callbacks = [ \n",
    "            EarlyStopping(patience=4, verbose=1), \n",
    "            ReduceLROnPlateau(factor=0.5, cooldown=0, patience=3, min_lr=0.5e-6), \n",
    "            CSVLogger(f'results/{dataset}/{preTrainedModel}.csv'), \n",
    "            ModelCheckpoint(f'results/{dataset}/{preTrainedModel}.hdf5', monitor = 'val_Accuracy', verbose = 1, mode='max', save_best_only=True) \n",
    "        ]\n",
    "\n",
    "        model.fit(trainDataset, batch_size=batchSize, epochs=epochs, verbose=True, validation_data=validateDataset, shuffle=True, callbacks=callbacks)\n",
    "\n",
    "        model = load_model(f'results/{dataset}/{preTrainedModel}.hdf5', compile=False)\n",
    "        model.compile(optimizer = Adam(learning_rate=learningRate), loss = 'binary_crossentropy', metrics = ['Accuracy', 'Recall', 'Precision', 'TrueNegatives', 'TruePositives', 'FalsePositives', 'FalseNegatives'])\n",
    "\n",
    "        res = model.evaluate(testDataset, batch_size=batchSize) \n",
    "        result = dict()\n",
    "        metrics = ['loss', 'Accuracy', 'Recall', 'Precision', 'TrueNegatives', 'TruePositives', 'FalsePositives', 'FalseNegatives']\n",
    "        result = {metric:value for metric, value in zip(metrics, res)}\n",
    "\n",
    "        result['Model'] = preTrainedModel \n",
    "        result['F1_Score'] = [(2*result['Recall']*result['Precision'])/(result['Recall']+result['Precision'])]\n",
    "        result['Dataset'] = dataset\n",
    "        df = pd.DataFrame(result) \n",
    "        results = pd.concat([results, df], axis=0)\n",
    "\n",
    "        clear_output(wait=True) \n",
    "\n",
    "train() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(path_or_buf='results/testResults/Results.csv', index=False)\n",
    "\n",
    "toLatex = results[[ 'Model', 'Dataset', 'Accuracy', 'Recall', 'Precision', 'F1_Score']]\n",
    "pickle.dump(toLatex.sort_values(by=['Model'], ascending=True).to_latex(index=False), open(\"results/testResults/Results.txt\", 'wb')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.copytree(\"/content/results\",\"/content/drive/MyDrive/results\", dirs_exist_ok=True) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9b01f5dcf6eb49e98361bda3ea635f308f2cf3e384d6b27fe94cf5889827908"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
