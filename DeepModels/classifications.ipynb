{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow -U "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import getModel \n",
    "from dataloader import data_pipeline #, data_pipeline_with_augmentation\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB5\n",
    "from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2B3\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.applications.regnet import RegNetX032 \n",
    "from tensorflow.keras.applications.xception import Xception \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, CSVLogger, EarlyStopping \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle, os, shutil\n",
    "from IPython.display import clear_output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "datasets = [\n",
    "    'classification(dilated-masks)',\n",
    "    'classification(dilated-masks)(withGAN)',\n",
    "    'classification(masks)',\n",
    "    'classification(withGAN)',\n",
    "    'classification(no-mask)',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "for dataset in datasets:\n",
    "    subprocess.Popen(f\"unzip 'drive/MyDrive/{dataset}.zip'\", shell=True) # run only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preTrained = {\n",
    "   'Xception' : dict(\n",
    "      modelFunction = Xception,\n",
    "      learningRate = 5e-6, \n",
    "      batchSize = 16,\n",
    "      dropout = [0.7, 0.5, 0.4],\n",
    "      trainbatchnorm = False,\n",
    "      denseSize = [4096, 4096, 4096]\n",
    "   ),\n",
    "   'VGG16' : dict(\n",
    "      modelFunction = VGG16,\n",
    "      learningRate = 5e-6, \n",
    "      batchSize = 16,\n",
    "      dropout = [0.7, 0.5, 0.4],\n",
    "      trainbatchnorm = False,\n",
    "      denseSize = [4096, 4096, 4096]\n",
    "   ),\n",
    "   'RegNetX032' : dict(\n",
    "      modelFunction = RegNetX032,\n",
    "      learningRate = 5e-6, \n",
    "      batchSize = 16,\n",
    "      dropout = [0.7, 0.5, 0.4],\n",
    "      trainbatchnorm = False,\n",
    "      denseSize = [4096, 4096, 4096]\n",
    "   ),\n",
    "   'MobileNetV2' : dict(\n",
    "      modelFunction = MobileNetV2,\n",
    "      learningRate = 5e-6, \n",
    "      batchSize = 16,\n",
    "      dropout = [0.7, 0.5, 0.4],\n",
    "      trainbatchnorm = False,\n",
    "      denseSize = [4096, 4096, 4096]\n",
    "   ),\n",
    "   'ResNet50V2' : dict(\n",
    "      modelFunction = ResNet50V2,\n",
    "      learningRate = 5e-6, \n",
    "      batchSize = 16,\n",
    "      dropout = [0.7, 0.5, 0.4],\n",
    "      trainbatchnorm = False,\n",
    "      denseSize = [4096, 4096, 4096]\n",
    "   ),\n",
    "   'EfficientNetV2B3' : dict(\n",
    "      modelFunction = EfficientNetV2B3,\n",
    "      learningRate = 5e-6, \n",
    "      batchSize = 16,\n",
    "      dropout = [0.7, 0.5, 0.4],\n",
    "      trainbatchnorm = False,\n",
    "      denseSize = [4096, 4096, 4096]\n",
    "   ),\n",
    "   'InceptionResNetV2' : dict(\n",
    "      modelFunction = InceptionResNetV2,\n",
    "      learningRate = 5e-6, \n",
    "      batchSize = 16,\n",
    "      dropout = [0.7, 0.5, 0.4],\n",
    "      trainbatchnorm = False,\n",
    "      denseSize = [4096, 4096, 4096]\n",
    "   ),\n",
    "   'EfficientNetB5' : dict(\n",
    "      modelFunction = EfficientNetB5,\n",
    "      learningRate = 5e-6, \n",
    "      batchSize = 16,\n",
    "      dropout = [0.7, 0.5, 0.4],\n",
    "      trainbatchnorm = False,\n",
    "      denseSize = [4096, 4096, 4096]\n",
    "   ),\n",
    "}\n",
    "\n",
    "# preTrained = [\n",
    "#    ('Xception', Xception, 1e-4, 16, 0.7),\n",
    "#    ('VGG16', VGG16, 5e-5, 8, 0.4),\n",
    "#    ('RegNetX032', RegNetX032, 5e-5, 8),\n",
    "#    ('MobileNetV2', MobileNetV2, 5e-5, 8),\n",
    "#    ('ResNet50V2', ResNet50V2, 5e-5, 8),\n",
    "#    ('EfficientNetV2B3', EfficientNetV2B3, 5e-6, 8),\n",
    "#    ('InceptionResNetV2', InceptionResNetV2, 5e-6, 8),\n",
    "#    ('EfficientNetB5', EfficientNetB5, 5e-6, 8),\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf results \n",
    "os.mkdir('results') \n",
    "for dataset in datasets:\n",
    "  os.mkdir(f'results/{dataset}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "  for preTrainedModel in preTrained.keys():\n",
    "      for dataset in datasets:\n",
    "        modelFunction, learningRate, batchSize, dropout, trainbatchnorm, denseSize = preTrained[preTrainedModel].values()\n",
    "        epochs = 15\n",
    "        trainDataset, validateDataset = data_pipeline(DIR=dataset, BATCHSIZE=batchSize, IMAGESIZE=(256, 256)) \n",
    "        model = getModel(modelFunction, learning_rate=learningRate, trainbatchnorm=trainbatchnorm, dropout=dropout, denseSize=denseSize)\n",
    "\n",
    "        callbacks = [ \n",
    "            EarlyStopping(patience=10, verbose=1), \n",
    "            ReduceLROnPlateau(factor=0.5, cooldown=0, patience=3, min_lr=0.5e-6), \n",
    "            CSVLogger(f'results/{dataset}/{preTrainedModel}.csv'), \n",
    "            ModelCheckpoint(f'results/{dataset}/{preTrainedModel}.hdf5', monitor = 'val_Accuracy', verbose = 1, mode='max', save_best_only=True) \n",
    "        ]\n",
    "\n",
    "        model.fit(trainDataset, batch_size=batchSize, epochs=epochs, verbose=True, validation_data=validateDataset, shuffle=True, callbacks=callbacks) \n",
    "        model.load_weights(f'results/{dataset}/{preTrainedModel}.hdf5')\n",
    "\n",
    "        results = model.get_metrics_result()\n",
    "        results = {metric:value.numpy() for metric, value in results.items()}\n",
    "        results['F1_Score'] = (2*results['recall']*results['precision'])/(results['recall']+results['precision']) \n",
    "        results['Dataset'] = dataset\n",
    "        results['learningRate'] = learningRate\n",
    "        results['batchSize'] = batchSize\n",
    "        results['epochs'] = epochs\n",
    "        df = pd.DataFrame([results])\n",
    "\n",
    "        acc = np.round(results['Accuracy'], decimals=2)\n",
    "        pickle.dump(df.to_latex(), open(\"results/%s/%s_report_acc=%.2f.txt\"%(dataset, preTrainedModel, acc), 'wb')) \n",
    "        clear_output(wait=True) \n",
    "\n",
    "train() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.copytree(\"/content/results\",\"/content/drive/MyDrive/results\", dirs_exist_ok=True) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9b01f5dcf6eb49e98361bda3ea635f308f2cf3e384d6b27fe94cf5889827908"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
